{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from rake_nltk import Rake\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(address):\n",
    "    if os.path.exists(address)==False:\n",
    "        print('path not found')\n",
    "    if address.endswith('.txt'):\n",
    "        f=open(address)\n",
    "        g=f.read()\n",
    "        return g\n",
    "    else:\n",
    "        print('Please give a txt file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_it(text,filename,address=os.getcwd()):\n",
    "    if os.path.exists(address)==False:\n",
    "        print('Path Not Found')\n",
    "    else:\n",
    "        with open(address+\"\\\\\"+filename+\".txt\", 'w') as f:\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url(link_provided):\n",
    "    ua = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "    from requests.exceptions import ConnectionError\n",
    "    try:\n",
    "        response = requests.get(link_provided, headers={\"User-Agent\": ua})\n",
    "    except ConnectionError:\n",
    "        print ('Failed to open url.')\n",
    "        return\n",
    "    if response.status_code!=200:\n",
    "        print(\"Bad response code :\", response.status_code, link_provided)\n",
    "        return\n",
    "    if response.status_code == 200:\n",
    "        f=response.content\n",
    "    from bs4 import  BeautifulSoup\n",
    "    text=BeautifulSoup(f,\"html.parser\")\n",
    "    text=text.getText()\n",
    "    text=text.strip()\n",
    "    text=text.rstrip('\\n')\n",
    "    text=\"\\n\".join(item for item in text.split('\\n') if item)\n",
    "    text=text.replace('\\n','.')\n",
    "    text=text.rstrip('\\n')\n",
    "    text = text.encode('utf-8').decode('ascii', 'ignore')\n",
    "    base=input(\"Give The Address where you want to save folder(Enter No if you want it to save in current directory, Enter yes if you don't want to save)\\n \")\n",
    "    if(str.lower(base)==\"no\"):\n",
    "        filename=input('Enter Filename:- \\nCaution:- It will change the current file, if exist, of the same name:\\n')\n",
    "        save_it(text,filename)\n",
    "    elif str.lower(base)==\"yes\":\n",
    "        return text\n",
    "    else:\n",
    "        filename=input('Enter Filename: \\n Caution:- It will change the current file, if exist, of the same name:\\n')\n",
    "        save_it(text,filename,base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_words_after_link(text,words):\n",
    "    words=str.lower(words)\n",
    "    for i in range(0,len(words)):\n",
    "        if words[i] in text:\n",
    "            print('Forbidden Word Found is ', words[i])\n",
    "            return\n",
    "    print(\"Forbidden words not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_words_before_link(link_provided,words):\n",
    "    link_provided=str.lower(link_provided)\n",
    "    for i in range(0,len(words)):\n",
    "        if words[i] in link_provided:\n",
    "            print('Contain Forbidden Words\\n')\n",
    "        else:\n",
    "            load_url(link_provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation=list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text=word_tokenize(text)\n",
    "    answer=[i for i  in text if i not in punctuation]\n",
    "    for i in range(0,len(answer)):\n",
    "        answer[i]=str.lower(answer[i])\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    newanswer=[]\n",
    "    for i in range(0,len(answer)):\n",
    "        if answer[i] not in stopwords:\n",
    "            newanswer.append(answer[i])\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    stem_text=[]\n",
    "    for i in range(0,len(newanswer)):\n",
    "        stem_text.append(porter_stemmer.stem(newanswer[i]))\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemm_text=[]\n",
    "    for i in range(0,len(stem_text)):\n",
    "        lemm_text.append(wordnet_lemmatizer.lemmatize(stem_text[i]))\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_it(words):\n",
    "    if isinstance(words,list):\n",
    "        text=\"\"\n",
    "        for i in range(0,len(words)):\n",
    "            text=text+words[i]\n",
    "    else:\n",
    "        text=words\n",
    "    wordclou = WordCloud(width = 800, height = 800,background_color ='white',\n",
    "                min_font_size = 10).generate(text)\n",
    "    plt.figure(figsize = (8, 8), facecolor = None)\n",
    "    plt.imshow(wordclou)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_it(words,n):\n",
    "    if isinstance(words,list):\n",
    "        text=\"\"\n",
    "        for i in range(0,len(words)):\n",
    "            text=text+words[i]\n",
    "    else:\n",
    "        text=words\n",
    "    r=Rake()\n",
    "    r.extract_keywords_from_text(text)\n",
    "    print(r.get_ranked_phrases()[0:n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
